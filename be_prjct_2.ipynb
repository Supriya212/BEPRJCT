{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from textblob import TextBlob\n",
    "import csv\n",
    "df = pd.read_csv(\"/home/shubhu/testing/newfinal.csv\")\n",
    "#ds = df.sample(frac=1)\n",
    "#ds.to_csv('/home/shubhu/testing/newfinal.csv')\n",
    "#print(df.head())\n",
    "y = df.label \n",
    "print(y.values)\n",
    "# Drop the `label` column\n",
    "df = df.drop(\"label\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.33, random_state=53)\n",
    "X_train.to_csv('/home/shubhu/testing/training.csv')\n",
    "y_train.to_csv('/home/shubhu/testing/trainlabels.csv')\n",
    "X_test.to_csv('/home/shubhu/testing/testing.csv')\n",
    "y_test.to_csv('/home/shubhu/testing/testlabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi1\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "abc = [] #list for tfidf\n",
    "all =[] #list for adding features in csv\n",
    "\n",
    "df = pd.read_csv(\"/home/shubhu/testing/training.csv\")\n",
    "\n",
    "while (count < len(df.index)):\n",
    "     v = df['text'].values[count].strip(\"b'\")\n",
    "     #print(v)#cleaned text\n",
    "     abc.append(v)\n",
    "     analysis = TextBlob(v)\n",
    "     \n",
    "     ratio = df['friends_count'].values[count]/df['followers_count'].values[count]\n",
    "     #print(ratio)\n",
    "     if df['verified'].values[count]:\n",
    "        w = 1\n",
    "     else:\n",
    "        w = 0\n",
    "        \n",
    "     x = analysis.sentiment.polarity\n",
    "     if x< 0:\n",
    "            senti = 0\n",
    "            x =x*(-1)\n",
    "     elif x > 0:\n",
    "            senti = 1\n",
    "     else :\n",
    "            senti = 2\n",
    "\n",
    "     all.append([senti,x,analysis.sentiment.subjectivity,len(v),v.count('#'),ratio,\n",
    "                 df['statuses_count'].values[count],w,v.count('@'),v.count(\"http\"),v.count('!')])\n",
    "     count = count + 1\n",
    "\n",
    "with open('/home/shubhu/testing/trainfeatures.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"senti\",\"polarity\",\"subjectivity\",\"tweet_length\",\"No.of#\",\"ratio\",\"statuses_count\",\"verified\",\"No.of mentions\",\n",
    "                    \"No.of links\",\"No.of Exclamation\"])\n",
    "    writer.writerows(all)\n",
    "\n",
    "    \n",
    "#TFIDF feature\n",
    "#tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7) \n",
    "\n",
    "# Fit and transform the training data \n",
    "\n",
    "\n",
    "    \n",
    "print(\"hi1\")\n",
    "#type( df['friends_count'].values[0])       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi2\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "xyz = [] #list for tfidf\n",
    "all =[] #list for adding features in csv\n",
    "\n",
    "df = pd.read_csv(\"/home/shubhu/testing/testing.csv\")\n",
    "\n",
    "while (count < len(df.index)):\n",
    "     v = df['text'].values[count].strip(\"b'\")\n",
    "     #print(v)#cleaned text\n",
    "     xyz.append(v)\n",
    "     analysis = TextBlob(v)\n",
    "     #print(analysis.sentiment.polarity)#polarity and subjectivity feature\n",
    "     #print(len(v))#length of text\n",
    "     #print(v.count('#'))#No. of \"#\"\n",
    "     ratio = df['friends_count'].values[count]/df['followers_count'].values[count]\n",
    "     #print(ratio)\n",
    "     if df['verified'].values[count]:\n",
    "        w = 1\n",
    "     else :\n",
    "        w = 0\n",
    "     #print(w)\n",
    "     x = analysis.sentiment.polarity\n",
    "     if x< 0:\n",
    "            senti = 0\n",
    "            x =x*(-1)\n",
    "     elif x > 0:\n",
    "            senti = 1\n",
    "     else :\n",
    "            senti = 2\n",
    "     \n",
    "     all.append([senti,x,analysis.sentiment.subjectivity,len(v),v.count('#'),ratio,\n",
    "                 df['statuses_count'].values[count],w])\n",
    "     count = count + 1\n",
    "\n",
    "with open('/home/shubhu/testing/testfeatures.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"senti\",\"polarity\",\"subjectivity\",\"tweet_length\",\"No.of#\",\"ratio\",\"statuses_count\",\"verified\"])\n",
    "    writer.writerows(all)\n",
    "    #print(all)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7) \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(abc) \n",
    "# Fit and transform the training data \n",
    "tfidf_test = tfidf_vectorizer.transform(xyz) \n",
    "\n",
    "print(\"hi2\")   \n",
    "#type( df['followers_count'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(tfidf_train,y_train)\n",
    "print(\"hi3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.835\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(tfidf_test)\n",
    "scorenb1 = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % scorenb1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi3\n"
     ]
    }
   ],
   "source": [
    "dftrain = pd.read_csv('/home/shubhu/testing/trainfeatures.csv')\n",
    "dftest = pd.read_csv('/home/shubhu/testing/testfeatures.csv')\n",
    "\n",
    "dftrain = dftrain.values # to convert df to nd array\n",
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(dftrain,y_train)\n",
    "print(\"hi3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.619\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dftest)\n",
    "scorenb2 = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % scorenb2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier(criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dftrain, y_train)\n",
    "#model.score(dftrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "predicted= model.predict(dftest)\n",
    "scoredt2 = model.score(dftest,y_test)\n",
    "print(\"The prediction accuracy is: \",model.score(dftest,y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "dftrain = sc.fit_transform(dftrain)  \n",
    "dftest = sc.transform(dftest)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)  \n",
    "regressor.fit(dftrain, y_train)  \n",
    "y_pred = regressor.predict(dftest)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20752     0]\n",
      " [    0 51092]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20752\n",
      "           1       1.00      1.00      1.00     51092\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     71844\n",
      "   macro avg       1.00      1.00      1.00     71844\n",
      "weighted avg       1.00      1.00      1.00     71844\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "scorerf2 = accuracy_score(y_test, y_pred)\n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier(criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  84.85050943711374 %\n"
     ]
    }
   ],
   "source": [
    "predicted= model.predict(tfidf_test)\n",
    "scoredt1 = model.score(tfidf_test,y_test)\n",
    "print(\"The prediction accuracy is: \",model.score(tfidf_test,y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)  \n",
    "regressor.fit(tfidf_train, y_train)  \n",
    "y_pred = regressor.predict(tfidf_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16961  3791]\n",
      " [ 3788 47304]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82     20752\n",
      "           1       0.93      0.93      0.93     51092\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     71844\n",
      "   macro avg       0.87      0.87      0.87     71844\n",
      "weighted avg       0.89      0.89      0.89     71844\n",
      "\n",
      "0.8945075441233784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "scorerf1 = accuracy_score(y_test, y_pred)\n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
